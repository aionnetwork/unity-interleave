\section{Protocol Description}
\label{unity}

We keep and maintain the notion of difficulty provided by Proof of Work, as well as the general goal of the consensus protocol, which is agreement on canonical ordering of blocks. We introduce an alternative block generation scheme utilizing \textbf{stake} or \textbf{voting power} while maintaining the constructs own notion of difficulty. To facilitate this, we introduce a mechanism to obtain \textbf{stake} in the network by locking up network currency associated with each account. To maintain a split between the two types of blocks, we introduce a new rule that enforces the \textit{interleaving} behaviour, in that blocks must reference a parent of the opposing type. Finally, we introduce a fork choice rule that determines agreement on a canonical chain based upon an intermediate unit derived from the difficulty of both block generation algorithms. We show that this approach leads to an increase in security against certain attacks \S\ref{analysis}.

In order to forge a PoS block, a staker must have already registered some stake in a previous block. The exact mechanism of how stake is registered is an implementation detail; for a summary of how the Open Application Network manages staking, see \cite{unity_design_spec}, and \S\ref{staking_mechanism} for a very brief overview. A PoS block has some waiting time associated with it, and will only be accepted by the network once this wait time has elapsed (measured from the parent PoW block). Every staker has a random wait time calculated for each block they try to produce; however, the expected wait time is inversely proportional to the amount a staker has staked. In short, the more one stakes, the less their wait times are expected to be. The percentage of blocks a staker should expect to win is their percentage of the total stake in the network.

\subsection{Staking}
\label{staking_mechanism}

Staking in this context refers to \textbf{locking} ones assets in return for voting power (alternatively known as stake). In our model, the act of locking ones assets can be done immediately (for example in the next block), the act of \textbf{unlocking} ones assets however is associated with a waiting period before one can re-acquire the assets (for example, the assets can be re-acquired after $x$ blocks). We ignore concepts of transferring and delegating (in the context of the protocol) as described in \cite{unity_design_spec}.

\subsection{PoW Block Generation}
\label{pow_block_generation}

Miners performing Proof of Work to generate the next block use a scheme similar to the introduced by Nakamoto in \cite{nakamoto2008}. Assuming a mining difficulty parameter ($d_w$), miners solve the following cryptographic puzzle,

\begin{equation}
\label{eq:pow_puzzle_equation}
H(b) \leq 2^{256} / d_w.
\end{equation}

The hash function ($H()$) is a deterministic random oracle that returns a random number in $N_{256}$, given an arbitrary byte array $b$ as input ($b$ is usually referred to as the \textit{nonce}). As the cryptographic puzzle is independent of any miner, the probability of a miner proposing a block is proportional to their computational power (number of permutations of $H()$ the miner can evaluate per unit time). The difficulty parameter ($d_w$) is used by the network to stabilize it's block production rate in the presence of dynamic hash power (see \S\ref{difficulty_adjustment}).

\subsection{PoS Block Generation}
\label{pos_block_generation}

The generation of PoS blocks is largely based on the Nxt forging algorithm \cite{popov2016probabilistic}. 

A PoS block has a field called \emph{seed}. A PoS block's seed is based on the seed of the previous PoS block in the chain, which is always the block's grandparent. The seed of block $n + 2$ is the block producer's signature upon the seed of block $n$ (i.e. in order to produce block $n+2$, the staker must obtain the seed for this block by signing the seed of the last PoS block (block $n$)).  

Any time a staker is trying to produce a PoS block, there is a certain waiting time that must elapse before the block is valid. This wait time is measured from the timestamp of the parent block. The wait time is determined by three factors: the new block's seed, $s$, the staker's total stake, $V$, and the difficulty of the block, $d_s$. The difficulty is calculated as described in \S\ref{difficulty_adjustment}. The wait time, $\Delta$, is inversely proportional to $V$, and directly proportional to $d_s$. The seed, $s$, provides some randomness to this calculation. We calculate the wait time as,

$$\Delta = \frac{d_s \cdot \log (\frac{2^{256}}{H(s)})}{V},$$

where $H$ is some hash function producing a 256-bit output.

The timestamp of a PoS block must be greater than or equal to the parent block's timestamp plus this $\Delta$. Honest nodes should thus only accept PoS blocks once the waiting time has elapsed .Further more, honest nodes must reject blocks with timestamps that are greater than their system time, so as to not accept block \emph{in the future}.  


\subsection{Fork choice rule}
\label{fork}

The \emph{fork choice rule} is the aspect of a consensus protocol that decides between two or more chains of valid blocks to decide what the ``canonical'' chain or ``main'' chain is. The fork choice rule for the protocol is to always choose the chain that maximises total difficulty, where total difficulty is simply the sum of the difficulties of all the blocks in the chain. Therefore, given a set of chains $D$, we denote the $i$th chain as $d_i$, and we denote $td_{s, d_i}$ and $td_{w, d_i}$ to be the total staking and work difficulties (respectively) for the $i$th chain. We recognize the main chain as the one that has in its prefix the genesis block, and that satisfies,

\begin{equation}
    M = \{td_{s, d_i} + td_{w, d_i} > td_{s, d_j} + td_{w, d_j} \forall j \neq i | d_i \in D \}
\end{equation}

In \S\ref{double_spend_attack} we examine why this fork choice rule is beneficial, compared to the one depicted in \cite{wu2019unifying}.

\subsection{Difficulty Adjustment}
\label{difficulty_adjustment}

We begin with the presumption that block arrival times for fast acting difficulty adjustment algorithms can be modelled using an exponential distribution. Note that this is not true in the case of a blockchain with a lagging difficulty adjustment algorithm such as Bitcoin \cite{block_arrivals}. This difficulty algorithm is applied identically to all blocks in the chain (i.e. both PoW and PoS blocks). Given that $\Delta$ represents the block arrival rates, the difficulty of the ($n+1$)th block (denoted $d_{n+1}$) is related the to the difficulty of the $n$th block (denoted $d_n$) via:

\begin{equation}
    d_{n+1} = \begin{cases}
        \frac{d_n}{1+\alpha}, & \Delta > -\frac{\log(1/2)}{\lambda} \\
        d_n, & \Delta = -\frac{\log(1/2)}{\lambda} \\
        d_{n} \cdot (1 + \alpha), & \Delta < -\frac{\log(1/2)}{\lambda} \\
    \end{cases}
\end{equation}

Where $\lambda$ represents the rate parameter for an exponential distribution. The $\alpha$ controls the learning rate, which further determines the responsiveness of the algorithm. The boundary value of $-\frac{\ln (0.5)}{\lambda}$ is calculated by solving,

\begin{equation}
    \label{eq:boundary}
    1-e^{(-\lambda x)}=0.5,
\end{equation}

where the left-hand side is the cumulative distribution function (cdf) of an exponential random variable. Where equation \ref{eq:boundary} refers to the time at which the probability of a block arriving or having already arrived is half. To give an example, in the live network we design our expected block time to be centered at 10 seconds, therefore we design the boundary to target an exponential distribution with a mean of 10. This gives us $\lambda^{-1}=10$. Solving $x$ for such a lambda gives us a boundary time of $x \approx 6.9314$.

Intuitively, this creates a negative feedback loop that stabilizes the system around 10 seconds. If the average difficulty is too high, it is reflected in the system by an increase in block time (on average), in which case the protocol responds by decreasing the difficulty. In the same vein, difficulty is adjusted upwards when the average block time is too low.
